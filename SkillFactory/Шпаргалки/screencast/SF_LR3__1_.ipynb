{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание датасета\n",
    "\n",
    "# with open('./data/adult.names', 'r') as f:\n",
    "#     names = f.read()\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  ...  \\\n",
       "0       0             0                       0                     0  ...   \n",
       "1       0             0                       0                     0  ...   \n",
       "2       0             0                       0                     0  ...   \n",
       "3       0             0                       0                     0  ...   \n",
       "4       0             0                       0                     0  ...   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                         0                         0            0   \n",
       "1                         0                         0            0   \n",
       "2                         0                         0            0   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       "0            0            1            0          1  \n",
       "1            0            1            0          1  \n",
       "2            0            1            0          1  \n",
       "3            0            0            0          1  \n",
       "4            0            0            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "\n",
       "   hours-per-week  salary  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0       -0.035429       0             0                       0   \n",
       "1       -2.222153       0             0                       0   \n",
       "2       -0.035429       0             0                       0   \n",
       "3       -0.035429       0             0                       0   \n",
       "4       -0.035429       0             0                       0   \n",
       "\n",
       "   workclass_ Local-gov  ...  relationship_ Own-child  \\\n",
       "0                     0  ...                        0   \n",
       "1                     0  ...                        0   \n",
       "2                     0  ...                        0   \n",
       "3                     0  ...                        0   \n",
       "4                     0  ...                        0   \n",
       "\n",
       "   relationship_ Unmarried  relationship_ Wife  race_ Amer-Indian-Eskimo  \\\n",
       "0                        0                   0                         0   \n",
       "1                        0                   0                         0   \n",
       "2                        0                   0                         0   \n",
       "3                        0                   0                         0   \n",
       "4                        0                   1                         0   \n",
       "\n",
       "   race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
       "0                         0            0            0            1   \n",
       "1                         0            0            0            1   \n",
       "2                         0            0            0            1   \n",
       "3                         0            1            0            0   \n",
       "4                         0            1            0            0   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0            0          1  \n",
       "1            0          1  \n",
       "2            0          1  \n",
       "3            0          1  \n",
       "4            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.18220152e+00,  3.62299888e-01,  6.22907129e-01, -1.59850366e-02,\n",
       "       -2.97874470e-01,  3.24397258e-01,  8.11280626e-01,  9.87311090e-01,\n",
       "        1.05574662e+00,  5.53494533e-01,  8.85025416e-01,  4.24799786e-01,\n",
       "        1.02420428e+00,  8.98087390e-01,  7.79500017e-02,  6.08930383e-01,\n",
       "        9.88443132e-04,  2.21719660e+00,  1.02543563e+00,  2.58558666e-01,\n",
       "       -1.39716497e+00,  3.38009780e-01,  2.32468515e-01,  1.14915955e+00,\n",
       "        1.42333149e+00,  5.34420479e-01, -6.37888463e-01,  7.95663040e-01,\n",
       "        9.74747564e-01,  9.95948149e-01,  8.40399041e-01,  9.64814314e-01,\n",
       "       -3.15524980e-01, -1.29220590e-02,  9.33962074e-01,  1.61096748e+00,\n",
       "        6.18223280e-01,  2.36520366e-01,  2.28275110e-02,  3.95775461e-01,\n",
       "        6.93612812e-03,  5.89057982e-01,  6.90788800e-01,  3.38583874e-01,\n",
       "        8.35398252e-01,  9.09710550e-01,  5.62066615e-01,  9.48510850e-01,\n",
       "        7.61509306e-01,  1.08787945e+00,  6.37883564e-01,  4.35222964e-01,\n",
       "        6.21876481e-01,  9.78308166e-01, -7.81877921e-02,  1.59897859e-01,\n",
       "        3.36378365e-01,  6.46143233e-01,  4.08394474e-01,  4.91984312e-01,\n",
       "       -7.85036544e-01,  7.68917996e-01,  5.20449527e-01,  6.11752440e-01,\n",
       "       -4.28230037e-01,  3.30697269e-01,  8.58881427e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовать ROC кривую\n",
    "def calc_and_plot_roc(y_true, y_pred_proba):\n",
    "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
    "y_pred_proba = sigmoid(X_valid, theta)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавление регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Оборачивание линейной регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegOptimizer():\n",
    "    def __init__(self, alpha, n_iters):\n",
    "        self.theta = None\n",
    "        self._alpha = alpha\n",
    "        self._n_iters = n_iters\n",
    "    \n",
    "    def gradient_step(self, theta, theta_grad):\n",
    "        return theta - self._alpha * theta_grad\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, X, y, start_theta, n_iters):\n",
    "        theta = start_theta.copy()\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            theta_grad = self.grad_func(X, y, theta)\n",
    "            theta = self.gradient_step(theta, theta_grad)\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        start_theta = np.ones(m)\n",
    "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(RegOptimizer):\n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = X.dot(self.theta)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "def prepare_boston_data():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    # Нормализовать даннные с помощью стандартной нормализации\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinReg(0.01, 500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 17.24, RMSE = 4.15\n"
     ]
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Оборачивание логистической регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegOptimizer):\n",
    "    def sigmoid(self, X, theta):\n",
    "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(X, self.theta)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = self.predict_proba(X) > 0.5\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adult_data():\n",
    "    adult = pd.read_csv('./data/adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "    # Избавиться от лишних признаков\n",
    "    adult.drop(['native-country'], axis=1, inplace=True)\n",
    "    # Сконвертировать целевой столбец в бинарные значения\n",
    "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "    # Сделать one-hot encoding для некоторых признаков\n",
    "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "    \n",
    "    # Нормализовать нуждающиеся в этом признаки\n",
    "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "    \n",
    "    # Разбить таблицу данных на матрицы X и y\n",
    "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "    y = adult['salary'].values\n",
    "\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(1., 300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
    "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Добавление регуляризатора в линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
    "А ее градиент по параметру $\\theta$:\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRegularized(LinReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Добавление регуляризатора в логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegRegularized(LogReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/adult.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9069cc0db869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogRegRegularized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_adult_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-07078e565f6b>\u001b[0m in \u001b[0;36mprepare_adult_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                \u001b[1;34m'education-num'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'marital-status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'occupation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                \u001b[1;34m'relationship'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'race'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'capital-gain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Избавиться от лишних признаков\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/adult.data'"
     ]
    }
   ],
   "source": [
    "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorba\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f7e7e3a162ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-e146081dbb15>\u001b[0m in \u001b[0;36mprint_logisitc_metrics\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'acc = {acc:.2f} F1-score = {f1:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorba\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-21300dcf7b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcalc_and_plot_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-f0b09e6a8eef>\u001b[0m in \u001b[0;36mcalc_and_plot_roc\u001b[1;34m(y_true, y_pred_proba)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_and_plot_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Посчитать значения ROC кривой и значение площади под кривой AUC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 776\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
